{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드값 고정\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 장비 설정\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 경로 설정\n",
    "train_path = 'FakeImageDetection_Dataset/train'\n",
    "valid_path = 'FakeImageDetection_Dataset/valid'\n",
    "\n",
    "class ResizeIfNeeded:\n",
    "    def __call__(self, image):\n",
    "        # 이미지의 가로, 세로 길이를 확인\n",
    "        width, height = image.size\n",
    "        \n",
    "        # 가로 또는 세로 길이가 224 미만인 경우를 확인하여 크기를 늘림\n",
    "        new_width = width if width >= 224 else 224\n",
    "        new_height = height if height >= 224 else 224\n",
    "        \n",
    "        # 이미지 크기를 변경\n",
    "        resized_image = image.resize((new_width, new_height), Image.BICUBIC)\n",
    "        return resized_image\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    # 가로 또는 세로가 224 미만일 경우 크기를 늘림\n",
    "    transforms.Lambda(ResizeIfNeeded()),\n",
    "    # 가로와 세로가 모두 224 이상일 경우 224x224로 랜덤 크롭\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    # 이미지를 PyTorch 텐서로 변환\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 훈련 데이터셋\n",
    "datasets_train = ImageFolder(train_path, transform=transform)\n",
    "# 검증 데이터셋\n",
    "datasets_valid = ImageFolder(valid_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c31b1586b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# 제너레이터 시드값 고정\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "loader_train = DataLoader(dataset=datasets_train, batch_size=batch_size, \n",
    "                          shuffle=True, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)\n",
    "loader_valid = DataLoader(dataset=datasets_valid, batch_size=batch_size, \n",
    "                          shuffle=False, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "# 모델 생성\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2) \n",
    "# 장비 할당\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguddnjs2366\u001b[0m (\u001b[33mseohw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\Desktop\\Workspace\\Thesis\\generative_image_detection\\Personal Research\\Resarch 1\\wandb\\run-20231105_190646-kj34u2r3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/kj34u2r3' target=\"_blank\">Research1_1</a></strong> to <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/kj34u2r3' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/kj34u2r3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/seohw/FakeImageDetection_Research/runs/kj34u2r3?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1c331bb8490>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# wandb 초기화: 새로운 실험을 생성하거나 기존 실험에 연결\n",
    "wandb.init(project=\"FakeImageDetection_Research\", name=\"Research1_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # 정확도 계산 함수\n",
    "from sklearn.metrics import recall_score   # 재현율 계산 함수\n",
    "from sklearn.metrics import f1_score       # F1 점수 계산 함수\n",
    "from tqdm.notebook import tqdm             # 진행률 표시 막대\n",
    "\n",
    "def train(model, loader_train, loader_valid, criterion, optimizer, \n",
    "          scheduler=None, epochs=10, save_file='model_state_dict.pth'):\n",
    "    \n",
    "    valid_loss_min = np.inf # 최소 손실값 초기화 (검증 데이터용) \n",
    "\n",
    "    # 총 에폭만큼 반복\n",
    "    for epoch in range(epochs):\n",
    "        print(f'에폭 [{epoch+1}/{epochs}] \\n-----------------------------')\n",
    "        \n",
    "        # == [ 훈련 ] ==============================================\n",
    "        model.train()        # 모델을 훈련 상태로 설정\n",
    "        epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n",
    "        train_preds_list = []  # 훈련 데이터 예측값 저장용 리스트 초기화\n",
    "        train_true_list = []   # 훈련 데이터 실젯값 저장용 리스트 초기화\n",
    "        # '반복 횟수'만큼 반복 \n",
    "        for images, labels in tqdm(loader_train):\n",
    "            # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 옵티마이저 내 기울기 초기화\n",
    "            optimizer.zero_grad()\n",
    "            # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n",
    "            outputs = model(images)\n",
    "            # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 현재 배치에서의 손실 추가 (훈련 데이터용)\n",
    "            epoch_train_loss += loss.item() \n",
    "            loss.backward()       # 역전파 수행\n",
    "            optimizer.step()      # 가중치 갱신\n",
    "            if scheduler != None: # 스케줄러 학습률 갱신 \n",
    "                scheduler.step() \n",
    "                \n",
    "            # 예측값 및 실제값 저장 (훈련 데이터용)\n",
    "            train_preds = torch.max(outputs.cpu(), dim=1)[1].numpy()\n",
    "            train_true = labels.cpu().numpy()\n",
    "            train_preds_list.extend(train_preds)\n",
    "            train_true_list.extend(train_true)\n",
    "            \n",
    "        # 훈련 데이터 정확도 계산\n",
    "        train_accuracy = accuracy_score(train_true_list, train_preds_list)\n",
    "\n",
    "        # 훈련 데이터 손실값 출력\n",
    "        print(f'\\t훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n",
    "        print(f'\\t훈련 데이터 정확도 : {train_accuracy:.4f}')\n",
    "        \n",
    "        # == [ 검증 ] ==============================================\n",
    "        model.eval()         # 모델을 평가 상태로 설정 \n",
    "        epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용)\n",
    "        preds_list = []      # 예측값 저장용 리스트 초기화\n",
    "        true_list = []       # 실젯값 저장용 리스트 초기화\n",
    "        \n",
    "        with torch.no_grad(): # 기울기 계산 비활성화\n",
    "            for images, labels in loader_valid:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_valid_loss += loss.item()\n",
    "                \n",
    "                # 예측값 및 실제값 \n",
    "                preds = torch.max(outputs.cpu(), dim=1)[1].numpy() \n",
    "                true = labels.cpu().numpy() \n",
    "    \n",
    "                preds_list.extend(preds)\n",
    "                true_list.extend(true)\n",
    "                \n",
    "        # 정확도, 재현율, F1 점수 계산\n",
    "        val_accuracy = accuracy_score(true_list, preds_list)\n",
    "        val_recall = recall_score(true_list, preds_list)\n",
    "        val_f1_score = f1_score(true_list, preds_list)\n",
    "\n",
    "        wandb.log({\"train_loss\": epoch_train_loss/len(loader_train),\n",
    "                   \"train_accuracy\" : train_accuracy,\n",
    "                   \"val_loss\": epoch_valid_loss/len(loader_valid), \n",
    "                   \"val_accuracy\": val_accuracy,\n",
    "                   \"val_recall\" : val_recall,\n",
    "                   \"val_f1_score\" : val_f1_score})\n",
    "        \n",
    "        # 검증 데이터 손실값 및 정확도, 재현율, F1점수 출력\n",
    "        print(f'\\t검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f}')\n",
    "        print(f'\\t정확도 : {val_accuracy:.4f} / 재현율 : {val_recall:.4f} / F1 점수 : {val_f1_score:.4f}')\n",
    "        # == [ 최적 모델 가중치 찾기 ] ==============================\n",
    "        # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장 \n",
    "        if epoch_valid_loss <= valid_loss_min: \n",
    "            print(f'\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장')\n",
    "            # 모델 가중치를 파일로 저장 \n",
    "            torch.save(model.state_dict(), save_file) \n",
    "            valid_loss_min = epoch_valid_loss # 최소 손실값 갱신 \n",
    "    return torch.load(save_file) # 저장한 모델 가중치를 불러와 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭 [1/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02f0664a8ce419288e2f5b192a31937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.1001\n",
      "\t훈련 데이터 정확도 : 0.9612\n",
      "\t검증 데이터 손실값 : 0.1189\n",
      "\t정확도 : 0.9623 / 재현율 : 0.9505 / F1 점수 : 0.9618\n",
      "\t### 검증 데이터 손실값 감소 (inf --> 7.4933). 모델 저장\n",
      "에폭 [2/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60abccf9df494b56bf14745c8c9d5dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0319\n",
      "\t훈련 데이터 정확도 : 0.9891\n",
      "\t검증 데이터 손실값 : 0.0734\n",
      "\t정확도 : 0.9732 / 재현율 : 0.9465 / F1 점수 : 0.9725\n",
      "\t### 검증 데이터 손실값 감소 (7.4933 --> 4.6272). 모델 저장\n",
      "에폭 [3/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee512087c2d34711b47125480bf00270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0226\n",
      "\t훈련 데이터 정확도 : 0.9909\n",
      "\t검증 데이터 손실값 : 0.0215\n",
      "\t정확도 : 0.9925 / 재현율 : 0.9985 / F1 점수 : 0.9925\n",
      "\t### 검증 데이터 손실값 감소 (4.6272 --> 1.3575). 모델 저장\n",
      "에폭 [4/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc0544ad9d84679867e598bbb35012c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0175\n",
      "\t훈련 데이터 정확도 : 0.9952\n",
      "\t검증 데이터 손실값 : 0.0239\n",
      "\t정확도 : 0.9930 / 재현율 : 0.9990 / F1 점수 : 0.9930\n",
      "에폭 [5/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112c5ba27c9948c5ac5cdd5e826dc6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0131\n",
      "\t훈련 데이터 정확도 : 0.9963\n",
      "\t검증 데이터 손실값 : 0.0113\n",
      "\t정확도 : 0.9965 / 재현율 : 0.9985 / F1 점수 : 0.9965\n",
      "\t### 검증 데이터 손실값 감소 (1.3575 --> 0.7110). 모델 저장\n",
      "에폭 [6/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c181eec60da74d4099dc9318ebcf2543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0130\n",
      "\t훈련 데이터 정확도 : 0.9953\n",
      "\t검증 데이터 손실값 : 0.0551\n",
      "\t정확도 : 0.9848 / 재현율 : 0.9730 / F1 점수 : 0.9846\n",
      "에폭 [7/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfe5744f51d4afd852748641acc1066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0130\n",
      "\t훈련 데이터 정확도 : 0.9947\n",
      "\t검증 데이터 손실값 : 0.0061\n",
      "\t정확도 : 0.9980 / 재현율 : 0.9975 / F1 점수 : 0.9980\n",
      "\t### 검증 데이터 손실값 감소 (0.7110 --> 0.3865). 모델 저장\n",
      "에폭 [8/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcee0fb557b34b829ceab4cc23929cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0086\n",
      "\t훈련 데이터 정확도 : 0.9969\n",
      "\t검증 데이터 손실값 : 0.0020\n",
      "\t정확도 : 0.9992 / 재현율 : 0.9990 / F1 점수 : 0.9992\n",
      "\t### 검증 데이터 손실값 감소 (0.3865 --> 0.1287). 모델 저장\n",
      "에폭 [9/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "458e35a6ebb14689bec76dafa9de0a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0088\n",
      "\t훈련 데이터 정확도 : 0.9969\n",
      "\t검증 데이터 손실값 : 0.2160\n",
      "\t정확도 : 0.9540 / 재현율 : 0.9080 / F1 점수 : 0.9518\n",
      "에폭 [10/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a581bb9b8e43228f856e93b2da3f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0092\n",
      "\t훈련 데이터 정확도 : 0.9970\n",
      "\t검증 데이터 손실값 : 0.0745\n",
      "\t정확도 : 0.9828 / 재현율 : 0.9655 / F1 점수 : 0.9824\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ee4902752c41959ef6d4301d884a9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▆▇███████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▄▇▇█▆██▁▅</td></tr><tr><td>val_f1_score</td><td>▂▄▇▇█▆██▁▆</td></tr><tr><td>val_loss</td><td>▅▃▂▂▁▃▁▁█▃</td></tr><tr><td>val_recall</td><td>▄▄███▆██▁▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.997</td></tr><tr><td>train_loss</td><td>0.00921</td></tr><tr><td>val_accuracy</td><td>0.98275</td></tr><tr><td>val_f1_score</td><td>0.98245</td></tr><tr><td>val_loss</td><td>0.07447</td></tr><tr><td>val_recall</td><td>0.9655</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Research1_1</strong> at: <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/kj34u2r3' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/kj34u2r3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231105_190646-kj34u2r3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model_state_dict = train(model = model,\n",
    "                         loader_train = loader_train, \n",
    "                         loader_valid = loader_valid,\n",
    "                         criterion = criterion, \n",
    "                         optimizer = optimizer)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 가중치 불러오기\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasets_test = ImageFolder('test_data', transform=transform)\n",
    "\n",
    "batch_sise = 256\n",
    "\n",
    "loader_test = DataLoader(dataset=datasets_test, batch_size=batch_size, \n",
    "                         shuffle=False, worker_init_fn=seed_worker,\n",
    "                         generator=g, num_workers=0)\n",
    "\n",
    "model.eval()  # 평가 모드로 전환\n",
    "\n",
    "# 3. 예측하기\n",
    "predictions = []\n",
    "\n",
    "for images, _ in loader_test:  # 레이블은 사용하지 않음\n",
    "    images = images.to(device)  # 장비 할당\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(prediction)\n",
    "\n",
    "# 4. 결과 저장\n",
    "df = pd.read_csv('./test_data/sample_submission.csv')\n",
    "df['answer'] = predictions\n",
    "df['answer'] = 1 - df['answer']\n",
    "df.to_csv('./test_data/research1_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
