{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드값 고정\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 장비 설정\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.fftpack\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 경로 설정\n",
    "train_path = 'FakeImageDetection_Dataset/train'\n",
    "valid_path = 'FakeImageDetection_Dataset/valid'\n",
    "\n",
    "class FourierCrop:\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert image to grayscale and numpy array\n",
    "        img_gray = img.convert(\"L\")\n",
    "        img_np = np.array(img_gray)\n",
    "\n",
    "        # Compute 2D Fourier Transform\n",
    "        f_transform = scipy.fftpack.fft2(img_np)\n",
    "\n",
    "        # Find the region with highest energy\n",
    "        magnitude = np.abs(f_transform)\n",
    "        idx_max_energy = np.unravel_index(np.argmax(magnitude, axis=None), img_np.shape)\n",
    "        x, y = idx_max_energy[1], idx_max_energy[0]\n",
    "\n",
    "        # Crop the region\n",
    "        crop = F.crop(img, y, x, self.output_size[1], self.output_size[0])\n",
    "        return crop\n",
    "    \n",
    "class ResizeIfNeeded:\n",
    "    def __call__(self, image):\n",
    "        # 이미지의 가로, 세로 길이를 확인\n",
    "        width, height = image.size\n",
    "        \n",
    "        # 가로 또는 세로 길이가 224 미만인 경우를 확인하여 크기를 늘림\n",
    "        new_width = width if width >= 224 else 224\n",
    "        new_height = height if height >= 224 else 224\n",
    "        \n",
    "        # 이미지 크기를 변경\n",
    "        resized_image = image.resize((new_width, new_height), Image.BICUBIC)\n",
    "        return resized_image\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    FourierCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 훈련 데이터셋\n",
    "datasets_train = ImageFolder(train_path, transform=transform)\n",
    "# 검증 데이터셋\n",
    "datasets_valid = ImageFolder(valid_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x154e462c530>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# 제너레이터 시드값 고정\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "loader_train = DataLoader(dataset=datasets_train, batch_size=batch_size, \n",
    "                          shuffle=True, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)\n",
    "loader_valid = DataLoader(dataset=datasets_valid, batch_size=batch_size, \n",
    "                          shuffle=False, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "# 모델 생성\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2) \n",
    "# 장비 할당\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguddnjs2366\u001b[0m (\u001b[33mseohw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\Desktop\\Workspace\\Thesis\\generative_image_detection\\Personal Research\\Resarch 1\\wandb\\run-20231106_023950-zt890xii</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/zt890xii' target=\"_blank\">Research1_5</a></strong> to <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/zt890xii' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/zt890xii</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/seohw/FakeImageDetection_Research/runs/zt890xii?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1549588d730>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# wandb 초기화: 새로운 실험을 생성하거나 기존 실험에 연결\n",
    "wandb.init(project=\"FakeImageDetection_Research\", name=\"Research1_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # 정확도 계산 함수\n",
    "from sklearn.metrics import recall_score   # 재현율 계산 함수\n",
    "from sklearn.metrics import f1_score       # F1 점수 계산 함수\n",
    "from tqdm.notebook import tqdm             # 진행률 표시 막대\n",
    "\n",
    "def train(model, loader_train, loader_valid, criterion, optimizer, \n",
    "          scheduler=None, epochs=10, save_file='model_state_dict.pth'):\n",
    "    \n",
    "    valid_loss_min = np.inf # 최소 손실값 초기화 (검증 데이터용) \n",
    "\n",
    "    # 총 에폭만큼 반복\n",
    "    for epoch in range(epochs):\n",
    "        print(f'에폭 [{epoch+1}/{epochs}] \\n-----------------------------')\n",
    "        \n",
    "        # == [ 훈련 ] ==============================================\n",
    "        model.train()        # 모델을 훈련 상태로 설정\n",
    "        epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n",
    "        train_preds_list = []  # 훈련 데이터 예측값 저장용 리스트 초기화\n",
    "        train_true_list = []   # 훈련 데이터 실젯값 저장용 리스트 초기화\n",
    "        # '반복 횟수'만큼 반복 \n",
    "        for images, labels in tqdm(loader_train):\n",
    "            # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 옵티마이저 내 기울기 초기화\n",
    "            optimizer.zero_grad()\n",
    "            # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n",
    "            outputs = model(images)\n",
    "            # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 현재 배치에서의 손실 추가 (훈련 데이터용)\n",
    "            epoch_train_loss += loss.item() \n",
    "            loss.backward()       # 역전파 수행\n",
    "            optimizer.step()      # 가중치 갱신\n",
    "            if scheduler != None: # 스케줄러 학습률 갱신 \n",
    "                scheduler.step() \n",
    "                \n",
    "            # 예측값 및 실제값 저장 (훈련 데이터용)\n",
    "            train_preds = torch.max(outputs.cpu(), dim=1)[1].numpy()\n",
    "            train_true = labels.cpu().numpy()\n",
    "            train_preds_list.extend(train_preds)\n",
    "            train_true_list.extend(train_true)\n",
    "            \n",
    "        # 훈련 데이터 정확도 계산\n",
    "        train_accuracy = accuracy_score(train_true_list, train_preds_list)\n",
    "\n",
    "        # 훈련 데이터 손실값 출력\n",
    "        print(f'\\t훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n",
    "        print(f'\\t훈련 데이터 정확도 : {train_accuracy:.4f}')\n",
    "        \n",
    "        # == [ 검증 ] ==============================================\n",
    "        model.eval()         # 모델을 평가 상태로 설정 \n",
    "        epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용)\n",
    "        preds_list = []      # 예측값 저장용 리스트 초기화\n",
    "        true_list = []       # 실젯값 저장용 리스트 초기화\n",
    "        \n",
    "        with torch.no_grad(): # 기울기 계산 비활성화\n",
    "            for images, labels in loader_valid:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_valid_loss += loss.item()\n",
    "                \n",
    "                # 예측값 및 실제값 \n",
    "                preds = torch.max(outputs.cpu(), dim=1)[1].numpy() \n",
    "                true = labels.cpu().numpy() \n",
    "    \n",
    "                preds_list.extend(preds)\n",
    "                true_list.extend(true)\n",
    "                \n",
    "        # 정확도, 재현율, F1 점수 계산\n",
    "        val_accuracy = accuracy_score(true_list, preds_list)\n",
    "        val_recall = recall_score(true_list, preds_list)\n",
    "        val_f1_score = f1_score(true_list, preds_list)\n",
    "\n",
    "        wandb.log({\"train_loss\": epoch_train_loss/len(loader_train),\n",
    "                   \"train_accuracy\" : train_accuracy,\n",
    "                   \"val_loss\": epoch_valid_loss/len(loader_valid), \n",
    "                   \"val_accuracy\": val_accuracy,\n",
    "                   \"val_recall\" : val_recall,\n",
    "                   \"val_f1_score\" : val_f1_score})\n",
    "        \n",
    "        # 검증 데이터 손실값 및 정확도, 재현율, F1점수 출력\n",
    "        print(f'\\t검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f}')\n",
    "        print(f'\\t정확도 : {val_accuracy:.4f} / 재현율 : {val_recall:.4f} / F1 점수 : {val_f1_score:.4f}')\n",
    "        # == [ 최적 모델 가중치 찾기 ] ==============================\n",
    "        # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장 \n",
    "        if epoch_valid_loss <= valid_loss_min: \n",
    "            print(f'\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장')\n",
    "            # 모델 가중치를 파일로 저장 \n",
    "            torch.save(model.state_dict(), save_file) \n",
    "            valid_loss_min = epoch_valid_loss # 최소 손실값 갱신 \n",
    "    return torch.load(save_file) # 저장한 모델 가중치를 불러와 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭 [1/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb7f9c917c54f2f8b4d5d4f2f394697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0924\n",
      "\t훈련 데이터 정확도 : 0.9646\n",
      "\t검증 데이터 손실값 : 0.7686\n",
      "\t정확도 : 0.7913 / 재현율 : 0.9815 / F1 점수 : 0.8246\n",
      "\t### 검증 데이터 손실값 감소 (inf --> 48.4188). 모델 저장\n",
      "에폭 [2/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b3e3151bc2440194ee98498d211d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0207\n",
      "\t훈련 데이터 정확도 : 0.9931\n",
      "\t검증 데이터 손실값 : 0.0095\n",
      "\t정확도 : 0.9970 / 재현율 : 0.9945 / F1 점수 : 0.9970\n",
      "\t### 검증 데이터 손실값 감소 (48.4188 --> 0.5995). 모델 저장\n",
      "에폭 [3/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2745dfc8674ccab42569a013fc93a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0121\n",
      "\t훈련 데이터 정확도 : 0.9960\n",
      "\t검증 데이터 손실값 : 0.0182\n",
      "\t정확도 : 0.9955 / 재현율 : 0.9970 / F1 점수 : 0.9955\n",
      "에폭 [4/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569f5cdb099f4e21b67827338b1f1cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0091\n",
      "\t훈련 데이터 정확도 : 0.9968\n",
      "\t검증 데이터 손실값 : 0.0131\n",
      "\t정확도 : 0.9970 / 재현율 : 0.9945 / F1 점수 : 0.9970\n",
      "에폭 [5/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6fb34b892794f0da83987f67202fb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0080\n",
      "\t훈련 데이터 정확도 : 0.9974\n",
      "\t검증 데이터 손실값 : 0.0037\n",
      "\t정확도 : 0.9990 / 재현율 : 0.9985 / F1 점수 : 0.9990\n",
      "\t### 검증 데이터 손실값 감소 (0.5995 --> 0.2311). 모델 저장\n",
      "에폭 [6/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b44ac3099634b089d67f1d968b49c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0059\n",
      "\t훈련 데이터 정확도 : 0.9984\n",
      "\t검증 데이터 손실값 : 0.0043\n",
      "\t정확도 : 0.9988 / 재현율 : 0.9975 / F1 점수 : 0.9987\n",
      "에폭 [7/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "558f3baef2334f3b8398406a963f8265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0096\n",
      "\t훈련 데이터 정확도 : 0.9963\n",
      "\t검증 데이터 손실값 : 0.0074\n",
      "\t정확도 : 0.9988 / 재현율 : 0.9975 / F1 점수 : 0.9987\n",
      "에폭 [8/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bf0b6f94e449c7abe55ea0dccc86d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0036\n",
      "\t훈련 데이터 정확도 : 0.9989\n",
      "\t검증 데이터 손실값 : 0.0314\n",
      "\t정확도 : 0.9922 / 재현율 : 0.9880 / F1 점수 : 0.9922\n",
      "에폭 [9/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d527720dc90d41e299771931cce8c715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0068\n",
      "\t훈련 데이터 정확도 : 0.9978\n",
      "\t검증 데이터 손실값 : 0.0079\n",
      "\t정확도 : 0.9985 / 재현율 : 0.9975 / F1 점수 : 0.9985\n",
      "에폭 [10/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169ea34915874f1ca1901f54eca40b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0064\n",
      "\t훈련 데이터 정확도 : 0.9980\n",
      "\t검증 데이터 손실값 : 0.0160\n",
      "\t정확도 : 0.9982 / 재현율 : 0.9965 / F1 점수 : 0.9982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e8190256044b509c0713747619fde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.111710…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▇▇███▇███</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁█████████</td></tr><tr><td>val_f1_score</td><td>▁█████████</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_recall</td><td>▁▆▇▆███▄█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.998</td></tr><tr><td>train_loss</td><td>0.00644</td></tr><tr><td>val_accuracy</td><td>0.99825</td></tr><tr><td>val_f1_score</td><td>0.99825</td></tr><tr><td>val_loss</td><td>0.01602</td></tr><tr><td>val_recall</td><td>0.9965</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Research1_5</strong> at: <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/zt890xii' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/zt890xii</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231106_023950-zt890xii\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model_state_dict = train(model = model,\n",
    "                         loader_train = loader_train, \n",
    "                         loader_valid = loader_valid,\n",
    "                         criterion = criterion, \n",
    "                         optimizer = optimizer)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 가중치 불러오기\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasets_test = ImageFolder('test_data', transform=transform)\n",
    "\n",
    "batch_sise = 256\n",
    "\n",
    "loader_test = DataLoader(dataset=datasets_test, batch_size=batch_size, \n",
    "                         shuffle=False, worker_init_fn=seed_worker,\n",
    "                         generator=g, num_workers=0)\n",
    "model.eval()  # 평가 모드로 전환\n",
    "\n",
    "# 3. 예측하기\n",
    "predictions = []\n",
    "\n",
    "for images, _ in loader_test:  # 레이블은 사용하지 않음\n",
    "    images = images.to(device)  # 장비 할당\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(prediction)\n",
    "\n",
    "# 4. 결과 저장\n",
    "df = pd.read_csv('./test_data/sample_submission.csv')\n",
    "df['answer'] = predictions\n",
    "df['answer'] = 1 - df['answer']\n",
    "df.to_csv('./test_data/research1_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
