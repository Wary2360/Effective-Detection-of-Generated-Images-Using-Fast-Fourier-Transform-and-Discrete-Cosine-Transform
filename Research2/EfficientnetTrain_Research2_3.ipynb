{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "import cv2  # OpenCV 라이브러리\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드값 고정\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 장비 설정\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.fftpack\n",
    "\n",
    "# 훈련, 검증, 테스트 데이터 경로 설정\n",
    "train_path = 'C:/Users/user/Desktop/Workspace/Thesis/generative_image_detection/Personal Research/FakeImageDetection_Dataset/train'\n",
    "valid_path = 'C:/Users/user/Desktop/Workspace/Thesis/generative_image_detection/Personal Research/FakeImageDetection_Dataset/valid'\n",
    "\n",
    "class PCATransform:\n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # 이미지를 numpy 배열로 변환\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # 차원을 변경하여 (height * width, num_channels) 형태로 만듭니다.\n",
    "        reshaped_image = image_np.reshape(-1, image_np.shape[2])\n",
    "\n",
    "        # PCA를 계산합니다.\n",
    "        pca = PCA(n_components=self.n_components)\n",
    "        transformed_image = pca.fit_transform(reshaped_image)\n",
    "\n",
    "        # 가중치를 2배로 조정합니다.\n",
    "        transformed_image *= 1.2\n",
    "\n",
    "        # 원래의 형태로 이미지를 변환합니다.\n",
    "        restored_image = pca.inverse_transform(transformed_image)\n",
    "        restored_image = restored_image.reshape(image_np.shape)\n",
    "\n",
    "        # 이미지를 다시 PIL 형태로 변환합니다.\n",
    "        transformed_image_pil = F.to_pil_image(restored_image.astype(np.uint8))\n",
    "\n",
    "        return transformed_image_pil\n",
    "    \n",
    "class FourierTransform:\n",
    "    def __call__(self, image):\n",
    "        # 이미지를 numpy 배열로 변환 (여기서 image는 PIL 이미지가 될 것으로 예상됩니다.)\n",
    "        image_np = np.array(image)\n",
    "\n",
    "        # 컬러 채널 분리\n",
    "        channel_results = []\n",
    "        for channel in range(image_np.shape[2]):  # RGB 채널을 가정합니다.\n",
    "            # 해당 채널에 대해 푸리에 변환 적용\n",
    "            f_transform = cv2.dft(np.float32(image_np[:, :, channel]), flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "            f_transform_shifted = np.fft.fftshift(f_transform)\n",
    "            f_transform_magnitude = 12 * np.log(cv2.magnitude(f_transform_shifted[:, :, 0], f_transform_shifted[:, :, 1]) + 1)\n",
    "            channel_results.append(f_transform_magnitude)\n",
    "\n",
    "        # 채널 결과를 쌓아 하나의 이미지로 복원합니다. (스택으로 복원)\n",
    "        magnitude_image = np.stack(channel_results, axis=2)\n",
    "\n",
    "        # 결과 이미지의 스케일을 조정합니다.\n",
    "        magnitude_image -= magnitude_image.min()  # 최소값을 0으로 설정\n",
    "        magnitude_image = magnitude_image / magnitude_image.max() * 255.0  # 최대값을 255로 조정\n",
    "        magnitude_image = magnitude_image.astype(np.uint8)\n",
    "\n",
    "        # 다시 PIL 이미지로 변환합니다.\n",
    "        transformed_image_pil = F.to_pil_image(magnitude_image)\n",
    "        \n",
    "        return transformed_image_pil\n",
    "    \n",
    "class ResizeIfNeeded:\n",
    "    def __call__(self, image):\n",
    "        # 이미지의 가로, 세로 길이를 확인\n",
    "        width, height = image.size\n",
    "        \n",
    "        # 가로 또는 세로 길이가 224 미만인 경우를 확인하여 크기를 늘림\n",
    "        new_width = width if width >= 224 else 224\n",
    "        new_height = height if height >= 224 else 224\n",
    "        \n",
    "        # 이미지 크기를 변경\n",
    "        resized_image = image.resize((new_width, new_height), Image.BICUBIC)\n",
    "        return resized_image\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    FourierTransform(),\n",
    "    PCATransform(n_components=3),\n",
    "    transforms.Lambda(ResizeIfNeeded()),\n",
    "    transforms.RandomCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 훈련 데이터셋\n",
    "datasets_train = ImageFolder(train_path, transform=transform)\n",
    "# 검증 데이터셋\n",
    "datasets_valid = ImageFolder(valid_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21649e0f710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# 제너레이터 시드값 고정\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "loader_train = DataLoader(dataset=datasets_train, batch_size=batch_size, \n",
    "                          shuffle=True, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)\n",
    "loader_valid = DataLoader(dataset=datasets_valid, batch_size=batch_size, \n",
    "                          shuffle=False, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "# 모델 생성\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2) \n",
    "# 장비 할당\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguddnjs2366\u001b[0m (\u001b[33mseohw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\Desktop\\Workspace\\Thesis\\generative_image_detection\\Personal Research\\Resarch 1\\wandb\\run-20231106_164201-as0w3c4e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/as0w3c4e' target=\"_blank\">Research2_3</a></strong> to <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/as0w3c4e' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/as0w3c4e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/seohw/FakeImageDetection_Research/runs/as0w3c4e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x21660998880>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# wandb 초기화: 새로운 실험을 생성하거나 기존 실험에 연결\n",
    "wandb.init(project=\"FakeImageDetection_Research\", name=\"Research2_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # 정확도 계산 함수\n",
    "from sklearn.metrics import recall_score   # 재현율 계산 함수\n",
    "from sklearn.metrics import f1_score       # F1 점수 계산 함수\n",
    "from tqdm.notebook import tqdm             # 진행률 표시 막대\n",
    "\n",
    "def train(model, loader_train, loader_valid, criterion, optimizer, \n",
    "          scheduler=None, epochs=10, save_file='Research2_3_.pth'):\n",
    "    \n",
    "    valid_loss_min = np.inf # 최소 손실값 초기화 (검증 데이터용) \n",
    "\n",
    "    # 총 에폭만큼 반복\n",
    "    for epoch in range(epochs):\n",
    "        print(f'에폭 [{epoch+1}/{epochs}] \\n-----------------------------')\n",
    "        \n",
    "        # == [ 훈련 ] ==============================================\n",
    "        model.train()        # 모델을 훈련 상태로 설정\n",
    "        epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n",
    "        train_preds_list = []  # 훈련 데이터 예측값 저장용 리스트 초기화\n",
    "        train_true_list = []   # 훈련 데이터 실젯값 저장용 리스트 초기화\n",
    "        # '반복 횟수'만큼 반복 \n",
    "        for images, labels in tqdm(loader_train):\n",
    "            # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 옵티마이저 내 기울기 초기화\n",
    "            optimizer.zero_grad()\n",
    "            # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n",
    "            outputs = model(images)\n",
    "            # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 현재 배치에서의 손실 추가 (훈련 데이터용)\n",
    "            epoch_train_loss += loss.item() \n",
    "            loss.backward()       # 역전파 수행\n",
    "            optimizer.step()      # 가중치 갱신\n",
    "            if scheduler != None: # 스케줄러 학습률 갱신 \n",
    "                scheduler.step() \n",
    "                \n",
    "            # 예측값 및 실제값 저장 (훈련 데이터용)\n",
    "            train_preds = torch.max(outputs.cpu(), dim=1)[1].numpy()\n",
    "            train_true = labels.cpu().numpy()\n",
    "            train_preds_list.extend(train_preds)\n",
    "            train_true_list.extend(train_true)\n",
    "            \n",
    "        # 훈련 데이터 정확도 계산\n",
    "        train_accuracy = accuracy_score(train_true_list, train_preds_list)\n",
    "\n",
    "        # 훈련 데이터 손실값 출력\n",
    "        print(f'\\t훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n",
    "        print(f'\\t훈련 데이터 정확도 : {train_accuracy:.4f}')\n",
    "        \n",
    "        # == [ 검증 ] ==============================================\n",
    "        model.eval()         # 모델을 평가 상태로 설정 \n",
    "        epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용)\n",
    "        preds_list = []      # 예측값 저장용 리스트 초기화\n",
    "        true_list = []       # 실젯값 저장용 리스트 초기화\n",
    "        \n",
    "        with torch.no_grad(): # 기울기 계산 비활성화\n",
    "            for images, labels in loader_valid:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_valid_loss += loss.item()\n",
    "                \n",
    "                # 예측값 및 실제값 \n",
    "                preds = torch.max(outputs.cpu(), dim=1)[1].numpy() \n",
    "                true = labels.cpu().numpy() \n",
    "    \n",
    "                preds_list.extend(preds)\n",
    "                true_list.extend(true)\n",
    "                \n",
    "        # 정확도, 재현율, F1 점수 계산\n",
    "        val_accuracy = accuracy_score(true_list, preds_list)\n",
    "        val_recall = recall_score(true_list, preds_list)\n",
    "        val_f1_score = f1_score(true_list, preds_list)\n",
    "\n",
    "        wandb.log({\"train_loss\": epoch_train_loss/len(loader_train),\n",
    "                   \"train_accuracy\" : train_accuracy,\n",
    "                   \"val_loss\": epoch_valid_loss/len(loader_valid), \n",
    "                   \"val_accuracy\": val_accuracy,\n",
    "                   \"val_recall\" : val_recall,\n",
    "                   \"val_f1_score\" : val_f1_score})\n",
    "        \n",
    "        # 검증 데이터 손실값 및 정확도, 재현율, F1점수 출력\n",
    "        print(f'\\t검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f}')\n",
    "        print(f'\\t정확도 : {val_accuracy:.4f} / 재현율 : {val_recall:.4f} / F1 점수 : {val_f1_score:.4f}')\n",
    "        # == [ 최적 모델 가중치 찾기 ] ==============================\n",
    "        # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장 \n",
    "        if epoch_valid_loss <= valid_loss_min: \n",
    "            print(f'\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장')\n",
    "            # 모델 가중치를 파일로 저장 \n",
    "            torch.save(model.state_dict(), save_file) \n",
    "            valid_loss_min = epoch_valid_loss # 최소 손실값 갱신 \n",
    "    return torch.load(save_file) # 저장한 모델 가중치를 불러와 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭 [1/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39aad57b08ba4396802c7c870560c40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.1207\n",
      "\t훈련 데이터 정확도 : 0.9531\n",
      "\t검증 데이터 손실값 : 0.8870\n",
      "\t정확도 : 0.5078 / 재현율 : 0.9795 / F1 점수 : 0.6655\n",
      "\t### 검증 데이터 손실값 감소 (inf --> 55.8782). 모델 저장\n",
      "에폭 [2/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f558e45d724d84be82d2de1875b6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0599\n",
      "\t훈련 데이터 정확도 : 0.9773\n",
      "\t검증 데이터 손실값 : 0.3964\n",
      "\t정확도 : 0.8635 / 재현율 : 0.8160 / F1 점수 : 0.8567\n",
      "\t### 검증 데이터 손실값 감소 (55.8782 --> 24.9738). 모델 저장\n",
      "에폭 [3/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80382f5f7ab64dc7917211bccfe7cc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0492\n",
      "\t훈련 데이터 정확도 : 0.9834\n",
      "\t검증 데이터 손실값 : 0.0758\n",
      "\t정확도 : 0.9718 / 재현율 : 0.9980 / F1 점수 : 0.9725\n",
      "\t### 검증 데이터 손실값 감소 (24.9738 --> 4.7758). 모델 저장\n",
      "에폭 [4/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eedd1cc4ef8453b89d934b46873a662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0362\n",
      "\t훈련 데이터 정확도 : 0.9859\n",
      "\t검증 데이터 손실값 : 0.0571\n",
      "\t정확도 : 0.9812 / 재현율 : 0.9670 / F1 점수 : 0.9810\n",
      "\t### 검증 데이터 손실값 감소 (4.7758 --> 3.5963). 모델 저장\n",
      "에폭 [5/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0402ff0d983496da46dec2c5de7eeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0324\n",
      "\t훈련 데이터 정확도 : 0.9878\n",
      "\t검증 데이터 손실값 : 0.2162\n",
      "\t정확도 : 0.9230 / 재현율 : 0.9890 / F1 점수 : 0.9278\n",
      "에폭 [6/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347897a58e7f4cd7a18ad5129915dbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0314\n",
      "\t훈련 데이터 정확도 : 0.9897\n",
      "\t검증 데이터 손실값 : 0.1030\n",
      "\t정확도 : 0.9647 / 재현율 : 0.9945 / F1 점수 : 0.9658\n",
      "에폭 [7/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b94809ae35f404890f9af9553e50198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0281\n",
      "\t훈련 데이터 정확도 : 0.9906\n",
      "\t검증 데이터 손실값 : 0.0243\n",
      "\t정확도 : 0.9925 / 재현율 : 0.9930 / F1 점수 : 0.9925\n",
      "\t### 검증 데이터 손실값 감소 (3.5963 --> 1.5285). 모델 저장\n",
      "에폭 [8/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658cce583d30490fab4d2dedcadb8207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0266\n",
      "\t훈련 데이터 정확도 : 0.9904\n",
      "\t검증 데이터 손실값 : 0.0350\n",
      "\t정확도 : 0.9872 / 재현율 : 0.9965 / F1 점수 : 0.9874\n",
      "에폭 [9/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794c675ee4744cd3b1f4d3a8e9932b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0257\n",
      "\t훈련 데이터 정확도 : 0.9902\n",
      "\t검증 데이터 손실값 : 0.0253\n",
      "\t정확도 : 0.9918 / 재현율 : 0.9915 / F1 점수 : 0.9917\n",
      "에폭 [10/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6d6bd432e0403e8a03bc226330ca4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0268\n",
      "\t훈련 데이터 정확도 : 0.9901\n",
      "\t검증 데이터 손실값 : 0.4675\n",
      "\t정확도 : 0.8848 / 재현율 : 0.9780 / F1 점수 : 0.8946\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▆▇▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▃▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆██▇████▆</td></tr><tr><td>val_f1_score</td><td>▁▅██▇▇███▆</td></tr><tr><td>val_loss</td><td>█▄▁▁▃▂▁▁▁▅</td></tr><tr><td>val_recall</td><td>▇▁█▇█████▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.99006</td></tr><tr><td>train_loss</td><td>0.02685</td></tr><tr><td>val_accuracy</td><td>0.88475</td></tr><tr><td>val_f1_score</td><td>0.89458</td></tr><tr><td>val_loss</td><td>0.4675</td></tr><tr><td>val_recall</td><td>0.978</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Research2_3</strong> at: <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/as0w3c4e' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/as0w3c4e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231106_164201-as0w3c4e\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model_state_dict = train(model = model,\n",
    "                         loader_train = loader_train, \n",
    "                         loader_valid = loader_valid,\n",
    "                         criterion = criterion, \n",
    "                         optimizer = optimizer)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 가중치 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasets_test = ImageFolder('C:/Users/user/Desktop/Workspace/Thesis/generative_image_detection/Personal Research/test_data', transform=transform)\n",
    "\n",
    "batch_sise = 256\n",
    "\n",
    "loader_test = DataLoader(dataset=datasets_test, batch_size=batch_size, \n",
    "                         shuffle=False, worker_init_fn=seed_worker,\n",
    "                         generator=g, num_workers=0)\n",
    "model.eval()  # 평가 모드로 전환\n",
    "\n",
    "# 3. 예측하기\n",
    "predictions = []\n",
    "\n",
    "for images, _ in loader_test:  # 레이블은 사용하지 않음\n",
    "    images = images.to(device)  # 장비 할당\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        prediction = outputs.argmax(dim=1).cpu().numpy()\n",
    "        predictions.extend(prediction)\n",
    "\n",
    "# 4. 결과 저장\n",
    "df = pd.read_csv('C:/Users/user/Desktop/Workspace/Thesis/generative_image_detection/Personal Research/test_data/sample_submission.csv')\n",
    "df['answer'] = predictions\n",
    "df['answer'] = 1 - df['answer']\n",
    "df.to_csv('C:/Users/user/Desktop/Workspace/Thesis/generative_image_detection/Personal Research/test_data/research2_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
