{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from PIL import Image\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련, 검증, 테스트 데이터 경로 설정\n",
    "train_path = './Dataset/dct_train'\n",
    "valid_path = './Dataset/dct_valid'\n",
    "test_path = './Dataset/dct_test'\n",
    "n_patch = 5\n",
    "\n",
    "research_name = 'Resarch3_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드값 고정\n",
    "\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU 장비 설정\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import scipy.fftpack\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# 훈련 데이터셋\n",
    "datasets_train = ImageFolder(train_path, transform=transform)\n",
    "# 검증 데이터셋\n",
    "datasets_valid = ImageFolder(valid_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22a209e3b50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "# 제너레이터 시드값 고정\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "loader_train = DataLoader(dataset=datasets_train, batch_size=batch_size, \n",
    "                          shuffle=True, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)\n",
    "loader_valid = DataLoader(dataset=datasets_valid, batch_size=batch_size, \n",
    "                          shuffle=False, worker_init_fn=seed_worker,\n",
    "                          generator=g, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 모델 생성\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=2) \n",
    "# 장비 할당\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mguddnjs2366\u001b[0m (\u001b[33mseohw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e419abc10a6404199a766e9378c364d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016666666666666666, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\user\\Desktop\\Workspace\\Thesis\\generative_image_detection\\Personal Research\\Resarch 2\\wandb\\run-20231108_034404-lphocpuf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/lphocpuf' target=\"_blank\">Resarch3_3</a></strong> to <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/seohw/FakeImageDetection_Research' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/lphocpuf' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/lphocpuf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/seohw/FakeImageDetection_Research/runs/lphocpuf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x22a317f1610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# wandb 초기화: 새로운 실험을 생성하거나 기존 실험에 연결\n",
    "wandb.init(project=\"FakeImageDetection_Research\", name=research_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score # 정확도 계산 함수\n",
    "from sklearn.metrics import recall_score   # 재현율 계산 함수\n",
    "from sklearn.metrics import f1_score       # F1 점수 계산 함수\n",
    "from tqdm.notebook import tqdm             # 진행률 표시 막대\n",
    "\n",
    "def train(model, loader_train, loader_valid, criterion, optimizer, \n",
    "          scheduler=None, epochs=10, save_file=''):\n",
    "    \n",
    "    valid_loss_min = np.inf # 최소 손실값 초기화 (검증 데이터용) \n",
    "\n",
    "    # 총 에폭만큼 반복\n",
    "    for epoch in range(epochs):\n",
    "        print(f'에폭 [{epoch+1}/{epochs}] \\n-----------------------------')\n",
    "        \n",
    "        # == [ 훈련 ] ==============================================\n",
    "        model.train()        # 모델을 훈련 상태로 설정\n",
    "        epoch_train_loss = 0 # 에폭별 손실값 초기화 (훈련 데이터용)\n",
    "        train_preds_list = []  # 훈련 데이터 예측값 저장용 리스트 초기화\n",
    "        train_true_list = []   # 훈련 데이터 실젯값 저장용 리스트 초기화\n",
    "        # '반복 횟수'만큼 반복 \n",
    "        for images, labels in tqdm(loader_train):\n",
    "            # 이미지, 레이블(타깃값) 데이터 미니배치를 장비에 할당 \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # 옵티마이저 내 기울기 초기화\n",
    "            optimizer.zero_grad()\n",
    "            # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n",
    "            outputs = model(images)\n",
    "            # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n",
    "            loss = criterion(outputs, labels)\n",
    "            # 현재 배치에서의 손실 추가 (훈련 데이터용)\n",
    "            epoch_train_loss += loss.item() \n",
    "            loss.backward()       # 역전파 수행\n",
    "            optimizer.step()      # 가중치 갱신\n",
    "            if scheduler != None: # 스케줄러 학습률 갱신 \n",
    "                scheduler.step() \n",
    "                \n",
    "            # 예측값 및 실제값 저장 (훈련 데이터용)\n",
    "            train_preds = torch.max(outputs.cpu(), dim=1)[1].numpy()\n",
    "            train_true = labels.cpu().numpy()\n",
    "            train_preds_list.extend(train_preds)\n",
    "            train_true_list.extend(train_true)\n",
    "            \n",
    "        # 훈련 데이터 정확도 계산\n",
    "        train_accuracy = accuracy_score(train_true_list, train_preds_list)\n",
    "\n",
    "        # 훈련 데이터 손실값 출력\n",
    "        print(f'\\t훈련 데이터 손실값 : {epoch_train_loss/len(loader_train):.4f}')\n",
    "        print(f'\\t훈련 데이터 정확도 : {train_accuracy:.4f}')\n",
    "        \n",
    "        # == [ 검증 ] ==============================================\n",
    "        model.eval()         # 모델을 평가 상태로 설정 \n",
    "        epoch_valid_loss = 0 # 에폭별 손실값 초기화 (검증 데이터용)\n",
    "        preds_list = []      # 예측값 저장용 리스트 초기화\n",
    "        true_list = []       # 실젯값 저장용 리스트 초기화\n",
    "        \n",
    "        with torch.no_grad(): # 기울기 계산 비활성화\n",
    "            for images, labels in loader_valid:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                epoch_valid_loss += loss.item()\n",
    "                \n",
    "                # 예측값 및 실제값 \n",
    "                preds = torch.max(outputs.cpu(), dim=1)[1].numpy() \n",
    "                true = labels.cpu().numpy() \n",
    "    \n",
    "                preds_list.extend(preds)\n",
    "                true_list.extend(true)\n",
    "                \n",
    "        # 정확도, 재현율, F1 점수 계산\n",
    "        val_accuracy = accuracy_score(true_list, preds_list)\n",
    "        val_recall = recall_score(true_list, preds_list)\n",
    "        val_f1_score = f1_score(true_list, preds_list)\n",
    "\n",
    "        wandb.log({\"train_loss\": epoch_train_loss/len(loader_train),\n",
    "                   \"train_accuracy\" : train_accuracy,\n",
    "                   \"val_loss\": epoch_valid_loss/len(loader_valid), \n",
    "                   \"val_accuracy\": val_accuracy,\n",
    "                   \"val_recall\" : val_recall,\n",
    "                   \"val_f1_score\" : val_f1_score})\n",
    "        \n",
    "        # 검증 데이터 손실값 및 정확도, 재현율, F1점수 출력\n",
    "        print(f'\\t검증 데이터 손실값 : {epoch_valid_loss/len(loader_valid):.4f}')\n",
    "        print(f'\\t정확도 : {val_accuracy:.4f} / 재현율 : {val_recall:.4f} / F1 점수 : {val_f1_score:.4f}')\n",
    "        # == [ 최적 모델 가중치 찾기 ] ==============================\n",
    "        # 현 에폭에서의 손실값이 최소 손실값 이하면 모델 가중치 저장 \n",
    "        if epoch_valid_loss <= valid_loss_min: \n",
    "            print(f'\\t### 검증 데이터 손실값 감소 ({valid_loss_min:.4f} --> {epoch_valid_loss:.4f}). 모델 저장')\n",
    "            # 모델 가중치를 파일로 저장 \n",
    "            torch.save(model.state_dict(), f'./Predict/{save_file}/'+ save_file + f'_{epoch}epoch.pth') \n",
    "            valid_loss_min = epoch_valid_loss # 최소 손실값 갱신 \n",
    "            high_epoch = epoch\n",
    "            \n",
    "        if epoch == 9:\n",
    "            torch.save(model.state_dict(), f'./Predict/{save_file}/'+ save_file + f'_lastepoch.pth') \n",
    "            \n",
    "    return torch.load(f'./Predict/{save_file}/'+ save_file + f'_{high_epoch}epoch.pth') # 저장한 모델 가중치를 불러와 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에폭 [1/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd24c61c71c4f6cadfd55524edb758b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0353\n",
      "\t훈련 데이터 정확도 : 0.9872\n",
      "\t검증 데이터 손실값 : 0.0416\n",
      "\t정확도 : 0.9850 / 재현율 : 0.9997 / F1 점수 : 0.9899\n",
      "\t### 검증 데이터 손실값 감소 (inf --> 9.9062). 모델 저장\n",
      "에폭 [2/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6bd7bdcb1849d79d2b06e576f6b477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0097\n",
      "\t훈련 데이터 정확도 : 0.9968\n",
      "\t검증 데이터 손실값 : 0.0576\n",
      "\t정확도 : 0.9790 / 재현율 : 1.0000 / F1 점수 : 0.9859\n",
      "에폭 [3/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb2e378e89a45beb024bf94403e48d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0068\n",
      "\t훈련 데이터 정확도 : 0.9976\n",
      "\t검증 데이터 손실값 : 0.0077\n",
      "\t정확도 : 0.9972 / 재현율 : 0.9961 / F1 점수 : 0.9981\n",
      "\t### 검증 데이터 손실값 감소 (9.9062 --> 1.8363). 모델 저장\n",
      "에폭 [4/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a9092b40f14c42b633fac7f920b23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0097\n",
      "\t훈련 데이터 정확도 : 0.9970\n",
      "\t검증 데이터 손실값 : 0.0018\n",
      "\t정확도 : 0.9994 / 재현율 : 0.9994 / F1 점수 : 0.9996\n",
      "\t### 검증 데이터 손실값 감소 (1.8363 --> 0.4303). 모델 저장\n",
      "에폭 [5/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c17e94de774542b9c769da34d4959d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0042\n",
      "\t훈련 데이터 정확도 : 0.9986\n",
      "\t검증 데이터 손실값 : 0.0381\n",
      "\t정확도 : 0.9893 / 재현율 : 1.0000 / F1 점수 : 0.9927\n",
      "에폭 [6/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5b9fd25a7a431d924b0b946f9e266e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0049\n",
      "\t훈련 데이터 정확도 : 0.9982\n",
      "\t검증 데이터 손실값 : 0.1890\n",
      "\t정확도 : 0.9381 / 재현율 : 0.9154 / F1 점수 : 0.9558\n",
      "에폭 [7/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059ecd1e93e644bd9d8db84641ef9272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0035\n",
      "\t훈련 데이터 정확도 : 0.9987\n",
      "\t검증 데이터 손실값 : 0.0032\n",
      "\t정확도 : 0.9989 / 재현율 : 0.9991 / F1 점수 : 0.9993\n",
      "에폭 [8/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a57bd95c13146d18d58490bcefd4457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0041\n",
      "\t훈련 데이터 정확도 : 0.9988\n",
      "\t검증 데이터 손실값 : 0.0027\n",
      "\t정확도 : 0.9994 / 재현율 : 0.9992 / F1 점수 : 0.9996\n",
      "에폭 [9/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f03e8acf6e4c7ba1c39c2ac298bb0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0039\n",
      "\t훈련 데이터 정확도 : 0.9986\n",
      "\t검증 데이터 손실값 : 0.0037\n",
      "\t정확도 : 0.9988 / 재현율 : 0.9996 / F1 점수 : 0.9992\n",
      "에폭 [10/10] \n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ea30de27134943bb17765aefe7fb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t훈련 데이터 손실값 : 0.0026\n",
      "\t훈련 데이터 정확도 : 0.9990\n",
      "\t검증 데이터 손실값 : 0.0044\n",
      "\t정확도 : 0.9990 / 재현율 : 1.0000 / F1 점수 : 0.9993\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "892075d233fc481ebd6dd247cee28806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>▁▇▇▇██████</td></tr><tr><td>train_loss</td><td>█▃▂▃▁▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆▆██▇▁████</td></tr><tr><td>val_f1_score</td><td>▆▆██▇▁████</td></tr><tr><td>val_loss</td><td>▂▃▁▁▂█▁▁▁▁</td></tr><tr><td>val_recall</td><td>█████▁████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_accuracy</td><td>0.99901</td></tr><tr><td>train_loss</td><td>0.00257</td></tr><tr><td>val_accuracy</td><td>0.99901</td></tr><tr><td>val_f1_score</td><td>0.99933</td></tr><tr><td>val_loss</td><td>0.00439</td></tr><tr><td>val_recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Resarch3_3</strong> at: <a href='https://wandb.ai/seohw/FakeImageDetection_Research/runs/lphocpuf' target=\"_blank\">https://wandb.ai/seohw/FakeImageDetection_Research/runs/lphocpuf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231108_034404-lphocpuf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(f'./Predict/{research_name}', exist_ok=True)\n",
    "# 모델 훈련\n",
    "model_state_dict = train(model = model,\n",
    "                         loader_train = loader_train, \n",
    "                         loader_valid = loader_valid,\n",
    "                         criterion = criterion, \n",
    "                         optimizer = optimizer,\n",
    "                         save_file = research_name)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최적 가중치 불러오기\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images_folder, transform=None):\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        # 폴더 내의 이미지 파일 리스트\n",
    "        self.image_filenames = [os.path.join(self.images_folder, file) for file in os.listdir(self.images_folder)\n",
    "                                if file.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 이미지 불러오기\n",
    "        image_path = self.image_filenames[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        # 변환 적용\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_patch start predict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910a61aa16ab4f84943126505bab0158",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_patch start predict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e270f9dcfc54d58a00267abd8172fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3_patch start predict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0935a3c196544ab916d4584462adb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4_patch start predict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b66589d54c49ff8462066a168db44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_patch start predict\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babc5b9910a44f2881099ae5cae954bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for i in range(n_patch):\n",
    "    print(f'{i+1}_patch start predict')\n",
    "    \n",
    "    datasets_test = CustomImageDataset(images_folder=test_path + f'/images_{i}', transform=transform)\n",
    "\n",
    "    batch_size = 256\n",
    "\n",
    "    loader_test = DataLoader(dataset=datasets_test, batch_size=batch_size, \n",
    "                            shuffle=False, worker_init_fn=seed_worker,\n",
    "                            generator=g, num_workers=0)\n",
    "    model.eval()  # 평가 모드로 전환\n",
    "\n",
    "    # 3. 예측하기\n",
    "    predictions = []\n",
    "\n",
    "    for image in tqdm(loader_test):\n",
    "        image = image.to(device)  # 장비 할당\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)\n",
    "            prediction = outputs.argmax(dim=1).cpu().numpy()\n",
    "            predictions.extend(prediction)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # 4. 결과 저장\n",
    "    df = pd.read_csv(r'C:\\Users\\user\\Desktop\\Workspace\\Thesis\\generative_image_detection\\Personal Research\\test_data\\sample_submission.csv')\n",
    "    df['answer'] = predictions\n",
    "    df.to_csv(f'./Predict/{research_name}/predict_{i}patch.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "from collections import Counter\n",
    "\n",
    "def hard_voting(csv_path, save_path):\n",
    "    csv_list = glob(f'{csv_path}/*.csv')\n",
    "\n",
    "    answer_columns = []\n",
    "\n",
    "    # Load each csv file\n",
    "    for csv_file in csv_list:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        answer_columns.append(df['answer'])\n",
    "\n",
    "    # Concatenate along the column axis\n",
    "    combined_answers = pd.concat(answer_columns, axis=1)\n",
    "\n",
    "    # Apply a lambda function to each row to find the most common value (mode)\n",
    "    voted_answers = combined_answers.apply(lambda row: Counter(row).most_common(1)[0][0], axis=1)\n",
    "\n",
    "    # Load first csv file to get 'ImageId' column\n",
    "    df = pd.read_csv(csv_list[0])\n",
    "    ImageId = df['ImageId']\n",
    "\n",
    "    # Create a new DataFrame with 'ImageId' and voted answers\n",
    "    result_df = pd.DataFrame({'ImageId': ImageId, 'answer': voted_answers})\n",
    "\n",
    "    # Save the result to a csv file\n",
    "    result_df.to_csv(f'{save_path}/voted_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_voting(f'./Predict/{research_name}', f'./Predict/{research_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
